# üöÄ ZIGGURAT MIND - RTX 4090 Implementation Plan

## üìã Project Overview

**Target System**: RTX 4090 24GB + i9-14900K + 32GB RAM  
**Timeline**: 3 weeks (2-3 weeks accelerated)  
**VRAM Strategy**: 75% utilization (18GB) with 25% safety margin  
**Architecture**: 5-level consciousness system with memory foundation

---

## üéØ Hardware Analysis & Strategy

### üìä VRAM Allocation (18GB utilized, 6GB reserved)

```rust
// Conservative VRAM distribution
pub struct VRamAllocation {
    mistral_7b: 14_000 MB,    // FP16 Mistral 7B
    embeddings_engine: 1_000 MB, // e5-small model + cache
    vector_store: 1_000 MB,     // GPU cached vectors
    system_buffer: 2_000 MB,    // Operations & buffers
    safety_margin: 6_000 MB,     // 25% reserve for stability
}
```

### üîß Optimized Parameters for RTX 4090

```rust
// priests/embeddings.rs - conservative configuration
pub struct EmbeddingConfig {
    pub embedding_dim: 384,        // e5-small optimal
    pub max_length: 512,           // Balanced for GPU
    pub batch_size: 32,            // Conservative for stability
    pub cache_size: 1000,          // Reduced from 2000
    pub normalize: true,           // For cosine similarity
}
```

### ‚ö° Expected Performance

```rust
// Performance targets with 25% safety margin
pub struct PerformanceTargets {
    embedding_speed: 500,         // texts/sec (batch 32)
    search_speed: 5_000,          // vectors/ms (GPU cache + RAM)
    generation_speed: 40,          // tokens/sec (unchanged)
    memory_capacity: 50_000,       // entries < 1GB VRAM
    vram_utilization: 75.0,        // % of total VRAM
}
```

---

## üóìÔ∏è Week-by-Week Implementation Plan

### üìÖ Week 1: Memory Foundation (Days 1-7)

#### **Day 1-2: Embedding Engine (Conservative)**
**File**: `src/priests/embeddings.rs`

**Objectives**:
- Complete existing 379-line implementation
- Add BERT-based model loading
- Implement conservative batch processing

**Key Features**:
```rust
pub struct EmbeddingEngine {
    model: BertModel,              // intfloat/multilingual-e5-small
    tokenizer: Tokenizer,          
    device: Device,                // CUDA RTX 4090
    cache: Arc<RwLock<HashMap<String, Vec<f32>>>>, // 1000 entries
}

impl EmbeddingEngine {
    pub fn with_conservative_config() -> EmbeddingConfig {
        EmbeddingConfig {
            batch_size: 32,           // ‚Üì from 64 for stability
            cache_size: 1000,         // ‚Üì from 2000 
            max_length: 512,           // optimal balance
            embedding_dim: 384,        // e5-small efficiency
        }
    }
    
    pub fn embed(&self, text: &str) -> Result<Vec<f32>>;
    pub fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>>;
    pub fn cosine_similarity(&self, a: &[f32], b: &[f32]) -> Result<f32>;
}
```

**VRAM Usage**: ~1GB (model + cache)

#### **Day 3-4: Vector Store (Memory-Efficient)**
**File**: `src/totems/retrieval/vector_store.rs`

**Objectives**:
- Implement tiered storage strategy
- Add GPU cache with RAM fallback
- Include lazy loading for scalability

**Key Features**:
```rust
pub struct VectorStore {
    entries: Vec<MemoryEntry>,           // In RAM
    dim: usize,                          
    gpu_cache: Option<LruCache<Uuid, Tensor>>, // GPU cache
    disk_path: Option<PathBuf>,           // Persistent storage
}

pub struct MemoryEntry {
    id: Uuid,
    text: String,
    embedding: Vec<f32>,                  // 384 dims = 1.5KB
    metadata: HashMap<String, String>,
    timestamp: DateTime<Utc>,
    memory_type: MemoryType,
    on_disk: bool,                        // Lazy loading flag
    disk_path: Option<PathBuf>,
}

impl VectorStore {
    pub fn add(&mut self, entry: MemoryEntry) -> Result<()>;
    pub fn search(&self, query_embedding: &[f32], top_k: usize) -> Vec<(f32, &MemoryEntry)>;
    pub fn search_hybrid(&self, query: &[f32], top_k: usize) -> Vec<(f32, &MemoryEntry)>;
    pub fn optimize_storage(&mut self) -> Result<()>;
}
```

**Storage Strategy**:
- **GPU Cache**: 1000 most recent vectors
- **RAM**: 10,000 recent entries
- **Disk**: Unlimited with lazy loading

#### **Day 5-7: Memory Management System**
**File**: `src/totems/memory.rs`

**Objectives**:
- Create intelligent memory manager
- Implement adaptive caching policies
- Add performance monitoring

**Key Features**:
```rust
pub struct MemoryManager {
    vector_store: VectorStore,
    memory_policy: MemoryPolicy,
    performance_monitor: PerformanceMonitor,
}

pub struct MemoryPolicy {
    pub max_gpu_entries: usize,           // 1000
    pub max_ram_entries: usize,           // 10000  
    pub max_total_entries: usize,         // 50000
    pub eviction_strategy: EvictionStrategy, // LRU + relevance
}

#[derive(Debug)]
pub enum EvictionStrategy {
    Lru,                                // Least Recently Used
    Relevance { threshold: f32 },        // Relevance-based
    Adaptive,                            // Smart combination
}

impl MemoryManager {
    pub fn add_entry(&mut self, entry: MemoryEntry) -> Result<()>;
    pub fn check_memory_pressure(&self) -> MemoryPressure;
    pub fn optimize_storage(&mut self) -> Result<()>;
}
```

**Week 1 Deliverables**:
- ‚úÖ Functional embedding engine with conservative settings
- ‚úÖ Tiered vector storage system
- ‚úÖ Memory management with monitoring
- ‚úÖ Performance benchmarks on RTX 4090

---

### üìÖ Week 2: Intelligent Memory System (Days 8-14)

#### **Day 8-9: Episodic Memory (Optimized)**
**File**: `src/totems/episodic/dialogue.rs`

**Objectives**:
- Implement dialogue management with memory efficiency
- Add smart caching strategies
- Include relevance-based recall

**Key Features**:
```rust
pub struct DialogueManager {
    current_session: Session,
    vector_store: Arc<RwLock<VectorStore>>,
    embedder: Arc<EmbeddingEngine>,
    cache_strategy: CacheStrategy,
}

#[derive(Debug)]
pub enum CacheStrategy {
    Recent { entries: usize },            // Last N entries
    Relevant { threshold: f32 },        // Above relevance threshold
    Adaptive {                           // Smart adaptation
        gpu_limit: usize,
        relevance_threshold: f32,
    },
}

impl DialogueManager {
    pub fn add_exchange(&mut self, user: String, assistant: String) -> Result<()>;
    pub fn recall_similar_dialogues(&self, query: &str, top_k: usize) -> Result<Vec<String>>;
    pub fn optimize_caching(&mut self) -> Result<()>;
}

#[derive(Serialize, Deserialize)]
pub struct Session {
    pub id: Uuid,
    pub persona_name: String,
    pub turns: Vec<Turn>,
    pub created_at: DateTime<Utc>,
    pub last_activity: DateTime<Utc>,
}

#[derive(Serialize, Deserialize)]
pub struct Turn {
    pub user: String,
    pub assistant: String,
    pub timestamp: DateTime<Utc>,
    pub embedding_id: Option<Uuid>,      // Link to vector store
}
```

**Optimization Features**:
- Batch size: 16 (conservative)
- Lazy embedding generation
- Intelligent relevance caching
- Automatic session management

#### **Day 10-11: Persistence Layer (Efficient)**
**File**: `src/totems/persistence.rs`

**Objectives**:
- Implement efficient storage system
- Add compression and indexing
- Include incremental saves

**Key Features**:
```rust
pub struct PersistenceManager {
    base_path: PathBuf,
    compression: CompressionType,
    chunk_size: usize,                   // 1000 entries per chunk
    indexing: bool,                      // B-tree indexing enabled
}

#[derive(Debug)]
pub enum CompressionType {
    None,                               // Fastest, no compression
    Lz4,                               // Balanced speed/size
    Zstd,                               // Maximum compression
}

impl PersistenceManager {
    pub fn save_incremental(&self, entries: &[MemoryEntry]) -> Result<()>;
    pub fn load_lazy(&self, query: &MemoryQuery) -> Result<LazyLoader>;
    pub fn create_index(&self) -> Result<MemoryIndex>;
    pub fn compact_storage(&self) -> Result<()>;
}

pub struct LazyLoader {
    pub total_entries: usize,
    pub loaded_entries: usize,
    pub chunks: Vec<PathBuf>,
}
```

**Storage Strategy**:
- Chunk size: 1000 entries (~1.5MB)
- Compression: lz4 for balance
- Indexing: B-tree for fast lookups
- Async background saves

#### **Day 12-14: Unified Memory System**
**File**: `src/totems/mod.rs` (updated)

**Objectives**:
- Create unified memory interface
- Integrate all memory components
- Add performance monitoring

**Key Features**:
```rust
pub struct MemorySystem {
    pub episodic: DialogueManager,
    pub semantic: KnowledgeBase,
    pub context_window: ContextWindow,
    pub memory_manager: MemoryManager,
    pub performance_monitor: PerformanceMonitor,
}

pub struct PerformanceMonitor {
    pub vram_usage: Arc<RwLock<f32>>,      // % VRAM usage
    pub ram_usage: Arc<RwLock<usize>>,       // MB RAM usage
    pub search_latency: Arc<RwLock<f64>>,    // ms search time
    pub cache_hit_rate: Arc<RwLock<f32>>,    // % cache hits
    pub total_operations: Arc<RwLock<usize>>,
}

impl MemorySystem {
    pub fn recall(&self, query: &str) -> Result<MemoryContext>;
    pub fn check_memory_pressure(&self) -> MemoryPressure;
    pub fn optimize_background(&mut self) -> Result<()>;
    pub fn get_performance_stats(&self) -> PerformanceStats;
}

pub struct MemoryContext {
    pub recent_dialogue: String,
    pub relevant_episodes: Vec<String>,
    pub relevant_knowledge: Vec<String>,
    pub confidence_score: f32,
    pub retrieval_time_ms: u64,
}

impl MemoryContext {
    pub fn format_for_prompt(&self, max_length: usize) -> String;
    pub fn is_relevant(&self, threshold: f32) -> bool;
}
```

**Week 2 Deliverables**:
- ‚úÖ Complete episodic memory system
- ‚úÖ Efficient persistence with compression
- ‚úÖ Unified memory management
- ‚úÖ Performance monitoring and optimization

---

### üìÖ Week 3: Integration & MVP (Days 15-21)

#### **Day 15-17: Main Loop Integration**
**File**: `src/main.rs` (major update)

**Objectives**:
- Integrate memory into generation loop
- Add conservative memory limits
- Implement monitoring and optimization

**Key Features**:
```rust
fn main() -> Result<()> {
    // Initialize with memory monitoring
    let memory_monitor = MemoryMonitor::new(0.75); // 75% VRAM limit
    
    let mut memory = totems::MemorySystem::with_limits(
        device.clone(),
        MemoryLimits {
            max_vram_percent: 75.0,
            max_ram_mb: 8192,           // 8GB of 32GB
            max_entries: 50000,          // Conservative limit
        }
    )?;
    
    println!("üèõÔ∏è ZIGGURAT MIND –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –ª–∏–º–∏—Ç–∞–º–∏");
    println!("üíæ VRAM Limit: 75% ({}GB)", 18.0);
    println!("üß† Memory Capacity: 50,000 entries");
    
    loop {
        let user_input = read_user_input()?;
        if user_input == "/exit" { break; }
        
        // 1. Check memory pressure
        if memory.check_pressure()? {
            println!("‚ö†Ô∏è High memory usage, optimizing...");
            memory.optimize_background()?;
        }
        
        // 2. Conservative memory recall
        let memory_context = memory.recall_conservative(&user_input, 3)?; // top-3 results
        
        // 3. Prompt formatting with limits
        let prompt = format_prompt_with_memory_limits(
            &user_input, 
            &memory_context, 
            2048 // max context length
        )?;
        
        // 4. Generation with monitoring
        let response = engine.generate_with_monitoring(&prompt, &memory_monitor)?;
        
        // 5. Efficient storage with optimization
        memory.add_exchange_optimized(user_input.clone(), response.clone())?;
        
        // 6. Display with memory stats
        println!("ü§ñ {}", response);
        
        if memory.entry_count() % 10 == 0 {
            let stats = memory.get_performance_stats();
            println!("üìä Memory: {} entries, {:.1}% VRAM, {:.1}% cache hit", 
                    stats.total_entries, stats.vram_usage, stats.cache_hit_rate);
        }
        
        // 7. Periodic background optimization
        if memory.entry_count() % 100 == 0 {
            memory.optimize_background()?;
        }
    }
    
    // Final save and cleanup
    memory.save_all()?;
    println!("üíæ Memory saved. Session complete.");
    Ok(())
}
```

**New CLI Arguments**:
```rust
#[derive(Parser, Debug)]
struct Args {
    // ... existing args ...
    
    /// Memory configuration
    #[arg(long, default_value = "50000")]
    max_memory_entries: usize,
    
    /// VRAM usage limit (0.0-1.0)
    #[arg(long, default_value = "0.75")]
    vram_limit: f32,
    
    /// Memory persistence directory
    #[arg(long, default_value = "./data/memory")]
    memory_dir: String,
    
    /// Show memory statistics
    #[arg(long)]
    memory_stats: bool,
    
    /// Clear all memory
    #[arg(long)]
    clear_memory: bool,
}
```

#### **Day 18-19: Semantic Memory (Lightweight)**
**File**: `src/totems/semantic/knowledge.rs`

**Objectives**:
- Implement lightweight knowledge extraction
- Add concept management
- Include relevance scoring

**Key Features**:
```rust
pub struct KnowledgeBase {
    vector_store: VectorStore,
    embedder: Arc<EmbeddingEngine>,
    concepts: HashMap<String, SimpleConcept>,
    extraction_policy: ExtractionPolicy,
}

pub struct SimpleConcept {
    pub name: String,
    pub definition: String,
    pub category: String,                // Minimal metadata
    pub importance: f32,                 // 0.0-1.0 priority
    pub source: String,                  // "dialogue", "manual", etc.
    pub created_at: DateTime<Utc>,
}

pub struct ExtractionPolicy {
    pub simple_patterns: bool,            // "X - —ç—Ç–æ Y" patterns
    pub confidence_threshold: f32,        // Minimum confidence
    pub max_concepts_per_turn: usize,    // Prevent overload
}

impl KnowledgeBase {
    pub fn extract_from_dialogue(&mut self, dialogue: &str) -> Result<usize>;
    pub fn query_knowledge(&self, question: &str, top_k: usize) -> Result<Vec<String>>;
    pub fn update_importance(&mut self, concept: &str, delta: f32) -> Result<()>;
    pub fn get_top_concepts(&self, limit: usize) -> Vec<SimpleConcept>;
}
```

**Extraction Strategy**:
- Simple pattern matching: "X - —ç—Ç–æ Y", "X –æ–∑–Ω–∞—á–∞–µ—Ç Y"
- Confidence scoring based on context
- Limited extraction per dialogue turn
- Manual concept importance adjustment

#### **Day 20-21: Testing & Optimization**
**File**: `tests/memory_tests.rs`

**Objectives**:
- Comprehensive stability testing
- Performance benchmarking
- Memory leak detection

**Test Suite**:
```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_memory_stress() -> Result<()> {
        // Test with 50,000 entries
        // Monitor VRAM usage
        // Verify 75% limit respected
    }
    
    #[test]
    fn test_vram_pressure() -> Result<()> {
        // Simulate high memory pressure
        // Test automatic optimization
        // Verify graceful degradation
    }
    
    #[test]
    fn test_long_running_stability() -> Result<()> {
        // Run for 1 hour simulated
        // Check for memory leaks
        // Verify consistent performance
    }
    
    #[test]
    fn test_persistence_reliability() -> Result<()> {
        // Save/load cycles
        // Corruption detection
        // Recovery testing
    }
}
```

**Performance Benchmarks**:
```rust
// benchmarks/memory_bench.rs
use criterion::{criterion_group, criterion_main, Criterion};

fn bench_embedding_performance(c: &mut Criterion) {
    c.bench_function("embed_batch_32", |b| {
        b.iter(|| embed_batch_test(32))
    });
}

fn bench_vector_search(c: &mut Criterion) {
    c.bench_function("search_50k_vectors", |b| {
        b.iter(|| search_test(50_000)
    });
}

fn bench_memory_recall(c: &mut Criterion) {
    c.bench_function("memory_recall_with_context", |b| {
        b.iter(|| memory_recall_test())
    });
}

criterion_group!(benches, bench_embedding_performance, bench_vector_search, bench_memory_recall);
criterion_main!(benches);
```

**Week 3 Deliverables**:
- ‚úÖ Complete memory-augmented generation
- ‚úÖ Conservative VRAM management
- ‚úÖ Performance monitoring and stats
- ‚úÖ Comprehensive test coverage
- ‚úÖ MVP ready for deployment

---

## üìä Expected Results & Success Metrics

### üéØ Performance Targets

```rust
pub struct MVPSuccessMetrics {
    // Memory Performance
    pub embedding_speed: u32,          // > 500 texts/sec
    pub search_speed: u32,              // > 5,000 vectors/ms
    pub memory_capacity: usize,         // > 50,000 entries
    
    // Resource Usage
    pub vram_utilization: f32,         // ~75% (18GB/24GB)
    pub ram_utilization: f32,          // ~25% (8GB/32GB)
    pub cache_hit_rate: f32,            // > 80%
    
    // Stability
    pub uptime_hours: u32,             // > 24 hours continuous
    pub memory_errors: u32,             // 0 OOM errors
    pub corruption_incidents: u32,      // 0 data corruption
    
    // Functionality
    pub contextual_accuracy: f32,        // > 85% relevant responses
    pub recall_precision: f32,           // > 90% accurate recall
    pub persistence_reliability: f32,     // 99.9% save/load success
}
```

### üìà Weekly Milestones

**Week 1 Complete**:
- [ ] Embedding engine with conservative settings
- [ ] Tiered vector storage system
- [ ] Memory management foundation
- [ ] Basic performance benchmarks

**Week 2 Complete**:
- [ ] Complete episodic memory system
- [ ] Efficient persistence layer
- [ ] Unified memory management
- [ ] Performance monitoring

**Week 3 Complete (MVP Ready)**:
- [ ] Memory-augmented generation
- [ ] Conservative resource management
- [ ] Comprehensive testing
- [ ] Production-ready deployment

### üèÜ MVP Success Criteria

When these are met, MVP is ready:

1. **‚úÖ Stable Memory System**
   - 50,000+ entries with < 1GB VRAM usage
   - 75% VRAM utilization maintained
   - Zero OOM errors in 24-hour test

2. **‚úÖ Contextual Intelligence**
   - Relevant memory recall in < 100ms
   - 85%+ contextual accuracy in responses
   - Automatic knowledge extraction working

3. **‚úÖ Production Stability**
   - 24+ hours continuous operation
   - 99.9% save/load reliability
   - Graceful degradation under pressure

4. **‚úÖ Developer Experience**
   - Clear CLI interface with memory commands
   - Real-time performance monitoring
   - Easy configuration and deployment

---

## üîß Technical Specifications

### üì¶ Dependencies to Add

```toml
[dependencies]
# Existing dependencies...
candle-core = { git = "https://github.com/huggingface/candle", rev = "f526033" }
candle-nn = { git = "https://github.com/huggingface/candle", rev = "f526033" }
candle-transformers = { git = "https://github.com/huggingface/candle", rev = "f526033" }
anyhow = "1"
clap = { version = "4.2", features = ["derive"] }
hf-hub = "0.4.1"
tokenizers = { version = "0.21.0", default-features = false, features = ["onig"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tracing = "0.1"
tracing-subscriber = "0.2"
tracing-chrome = "0.1"
image = { version = "0.25.2", default-features = false, features = ["jpeg", "png"] }

# New dependencies for memory system
bincode = "1.3"                      # Vector serialization
uuid = { version = "1.0", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
parking_lot = "0.12"                 # Fast RwLock
lru = "0.12"                        # LRU cache
lz4 = "1.24"                        # Fast compression
memmap2 = "0.9"                     # Memory mapped files
criterion = "0.5"                    # Benchmarking (dev-dependencies)

[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports"] }
tempfile = "3.8"
```

### üèóÔ∏è File Structure (Complete)

```
src/
‚îú‚îÄ‚îÄ main.rs                    ‚Üê Updated orchestrator with memory
‚îú‚îÄ‚îÄ utils.rs                   ‚Üê Reduced to essential functions
‚îú‚îÄ‚îÄ priests/                   ‚Üê üúÅ Level 1: Iron Priests
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs               ‚Üê Module exports
‚îÇ   ‚îú‚îÄ‚îÄ device.rs            ‚Üê GPU/CPU/Metal abstraction (complete)
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.rs        ‚Üê BERT embedding engine (implement)
‚îú‚îÄ‚îÄ totems/                    ‚Üê üúÉ Level 2: Memory Totems ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs               ‚Üê Unified memory system
‚îÇ   ‚îú‚îÄ‚îÄ memory.rs            ‚Üê Memory manager & monitoring
‚îÇ   ‚îú‚îÄ‚îÄ episodic/            ‚Üê Episodic memory system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dialogue.rs     ‚Üê Dialogue management
‚îÇ   ‚îú‚îÄ‚îÄ semantic/            ‚Üê Semantic memory system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ knowledge.rs     ‚Üê Knowledge base
‚îÇ   ‚îú‚îÄ‚îÄ retrieval/           ‚Üê Vector search & storage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_store.rs ‚Üê Tiered vector storage
‚îÇ   ‚îî‚îÄ‚îÄ persistence.rs       ‚Üê Disk storage & compression
‚îî‚îÄ‚îÄ logos/                     ‚Üê üúÇ Level 4: Logos (unchanged)
    ‚îú‚îÄ‚îÄ mod.rs
    ‚îú‚îÄ‚îÄ inference.rs         ‚Üê Candle wrapper (placeholder)
    ‚îú‚îÄ‚îÄ tokenizer.rs         ‚Üê TokenOutputStream (re-export)
    ‚îî‚îÄ‚îÄ sampling.rs          ‚Üê Sampling configs (placeholder)

tests/                          ‚Üê Test suite
‚îú‚îÄ‚îÄ memory_tests.rs             ‚Üê Memory system tests
‚îú‚îÄ‚îÄ integration_tests.rs        ‚Üê Full system tests
‚îî‚îÄ‚îÄ benchmarks/                ‚Üê Performance benchmarks
    ‚îî‚îÄ‚îÄ memory_bench.rs

data/                           ‚Üê Memory storage (git-ignored)
‚îú‚îÄ‚îÄ episodic/                   ‚Üê Dialogue history
‚îÇ   ‚îú‚îÄ‚îÄ sessions/              ‚Üê Session files
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.bin         ‚Üê Vector embeddings
‚îú‚îÄ‚îÄ semantic/                   ‚Üê Knowledge base
‚îÇ   ‚îú‚îÄ‚îÄ concepts.json          ‚Üê Structured knowledge
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.bin         ‚Üê Knowledge vectors
‚îî‚îÄ‚îÄ indexes/                    ‚Üê Search indexes
    ‚îú‚îÄ‚îÄ episodic.idx          ‚Üê Episode index
    ‚îî‚îÄ‚îÄ semantic.idx          ‚Üê Knowledge index
```

### üéÆ CLI Commands (Enhanced)

```bash
# Basic usage with memory
./target/release/ziggurat-mind.exe \
  --prompt "–†–∞—Å—Å–∫–∞–∂–∏ –æ –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Ñ–∏–∑–∏–∫–µ" \
  --temperature 0.7 \
  --sample-len 200 \
  --max-memory-entries 100000 \
  --vram-limit 0.75 \
  --memory-dir "./data/memory"

# Memory management commands
./target/release/ziggurat-mind.exe \
  --memory-stats \
  --memory-dir "./data/memory"

./target/release/ziggurat-mind.exe \
  --clear-memory \
  --memory-dir "./data/memory"

# Performance testing
./target/release/ziggurat-mind.exe \
  --benchmark-mode \
  --test-entries 50000 \
  --stress-test

# Configuration examples
./target/release/ziggurat-mind.exe \
  --show-config \
  --save-config \
  --memory-config "conservative"
```

---

## üöÄ Deployment & Usage

### üì• Quick Start (3 commands)

```bash
# 1. Build with CUDA support
cargo build --release --features cuda

# 2. Download embedding model
mkdir -p models/embeddings
# Models are auto-downloaded from HuggingFace

# 3. Run with memory enabled
./target/release/ziggurat-mind.exe \
  --prompt "–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å –Ω–∞—à –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä?" \
  --temperature 0.7
```

### üíæ Memory Storage Format

**Episodic Memory** (`data/episodic/sessions/`):
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "persona_name": "companion",
  "turns": [
    {
      "user": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
      "assistant": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –û—Ç–ª–∏—á–Ω–æ, —Å–ø–∞—Å–∏–±–æ. –ß—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ?",
      "timestamp": "2026-01-17T10:00:00Z",
      "embedding_id": "550e8400-e29b-41d4-a716-446655440001"
    }
  ],
  "created_at": "2026-01-17T10:00:00Z",
  "last_activity": "2026-01-17T10:05:00Z"
}
```

**Vector Storage** (`data/episodic/embeddings.bin`):
```
[Binary format using bincode]
- Header: magic_bytes, version, entry_count, dimension
- Entries: id, embedding_vec[384], metadata, timestamp
- Index: B-tree for fast lookup
```

### üìä Monitoring Interface

**Real-time Stats**:
```
üß† ZIGGURAT MIND Memory Stats
================================
Entries:      12,347 total
Episodes:     8,921 dialogues  
Concepts:     3,426 facts
VRAM Usage:   14.2GB / 18GB (78.9%)
Cache Hits:    89.2% efficiency
Search Time:   23ms avg (last 100)
Uptime:       2h 34m continuous

Recent Activity:
- Added dialogue: "–æ–±—Å—É–∂–¥–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π" (relevance: 0.89)
- Extracted concept: "Transformer –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞" (importance: 0.76)
- Optimized storage: freed 234MB VRAM
```

---

## üéØ Risk Management & Contingencies

### ‚ö†Ô∏è Potential Risks

1. **VRAM Overflow**
   - **Mitigation**: 25% safety margin + automatic optimization
   - **Detection**: Real-time monitoring every 10 operations
   - **Recovery**: Intelligent eviction + graceful degradation

2. **Performance Degradation**
   - **Mitigation**: Adaptive batch sizing + caching strategies
   - **Detection**: Latency monitoring + benchmark thresholds
   - **Recovery**: Background optimization + cache tuning

3. **Memory Corruption**
   - **Mitigation**: Checksums + atomic writes
   - **Detection**: Validation on every load
   - **Recovery**: Backups + repair utilities

4. **Model Compatibility**
   - **Mitigation**: Version checking + fallback models
   - **Detection**: Startup validation tests
   - **Recovery**: Automatic model download + configuration

### üîÑ Fallback Strategies

```rust
// Conservative fallback modes
pub enum OperationMode {
    Full,                               // All features, 75% VRAM
    Conservative,                        // Reduced features, 50% VRAM
    Minimal,                            // Basic memory, 25% VRAM
    Emergency,                          // Cacheless, 10% VRAM
}

impl MemorySystem {
    pub fn adapt_to_pressure(&mut self, pressure: MemoryPressure) -> Result<()> {
        match pressure {
            MemoryPressure::High => self.switch_to_conservative_mode()?,
            MemoryPressure::Critical => self.switch_to_minimal_mode()?,
            MemoryPressure::Emergency => self.switch_to_emergency_mode()?,
        }
        Ok(())
    }
}
```

---

## üìù Success Checklist

### ‚úÖ Week 1 Completion
- [ ] Embedding engine integrated and tested
- [ ] Vector store with tiered storage working
- [ ] Memory management with monitoring
- [ ] Performance benchmarks passing
- [ ] VRAM usage under 75% limit

### ‚úÖ Week 2 Completion  
- [ ] Episodic memory fully functional
- [ ] Persistence layer with compression
- [ ] Unified memory system integrated
- [ ] All memory types working together
- [ ] Storage optimization automated

### ‚úÖ Week 3 Completion (MVP)
- [ ] Memory-augmented generation working
- [ ] CLI interface with memory commands
- [ ] Comprehensive test coverage
- [ ] 24-hour stability verified
- [ ] Documentation complete

### üèÜ MVP Ready When:
- [ ] System runs 24+ hours without errors
- [ ] Memory recall accuracy > 85%
- [ ] VRAM usage consistently < 75%
- [ ] All CLI commands working
- [ ] Documentation covers all features

---

*Last Updated: 2026-01-17*  
*Hardware: RTX 4090 24GB + i9-14900K + 32GB RAM*  
*Strategy: Conservative 75% VRAM utilization with 25% safety margin*  
*Timeline: 3 weeks accelerated implementation*